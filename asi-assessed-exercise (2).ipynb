{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:33.054317Z",
     "iopub.status.busy": "2021-05-27T10:54:33.053870Z",
     "iopub.status.idle": "2021-05-27T10:54:33.066037Z",
     "shell.execute_reply": "2021-05-27T10:54:33.064617Z",
     "shell.execute_reply.started": "2021-05-27T10:54:33.054282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/santander-customer-transaction-prediction/sample_submission.csv\n",
      "/kaggle/input/santander-customer-transaction-prediction/train.csv\n",
      "/kaggle/input/santander-customer-transaction-prediction/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to space issues on my computer, I directly worked on kaggle, thus the path to retrieve the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:34.407676Z",
     "iopub.status.busy": "2021-05-27T10:54:34.407209Z",
     "iopub.status.idle": "2021-05-27T10:54:45.341020Z",
     "shell.execute_reply": "2021-05-27T10:54:45.339904Z",
     "shell.execute_reply.started": "2021-05-27T10:54:34.407638Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"/kaggle/input/santander-customer-transaction-prediction/train.csv\")\n",
    "X_df = data_df.iloc[:,2:].copy()\n",
    "y_df =  data_df.iloc[:,1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:45.342833Z",
     "iopub.status.busy": "2021-05-27T10:54:45.342536Z",
     "iopub.status.idle": "2021-05-27T10:54:45.796838Z",
     "shell.execute_reply": "2021-05-27T10:54:45.795785Z",
     "shell.execute_reply.started": "2021-05-27T10:54:45.342804Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train_df, y_test_df = train_test_split(\n",
    "    X_df, y_df, random_state=1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:45.798947Z",
     "iopub.status.busy": "2021-05-27T10:54:45.798649Z",
     "iopub.status.idle": "2021-05-27T10:54:45.804519Z",
     "shell.execute_reply": "2021-05-27T10:54:45.803279Z",
     "shell.execute_reply.started": "2021-05-27T10:54:45.798918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of label 1 : 0.10049\n"
     ]
    }
   ],
   "source": [
    "label_1 = y_df.sum()\n",
    "ratio = label_1/len(y_df)\n",
    "print('Ratio of label 1 : {}'.format(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 10% of the dataset is composed of the label 1 --> The dataset is not equilibrated. Therefore a good model should provide an accuracy above 90% as a predicting that all outputs are 0 would ensure such an accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:45.806333Z",
     "iopub.status.busy": "2021-05-27T10:54:45.806043Z",
     "iopub.status.idle": "2021-05-27T10:54:45.851531Z",
     "shell.execute_reply": "2021-05-27T10:54:45.850365Z",
     "shell.execute_reply.started": "2021-05-27T10:54:45.806305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.093</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.389</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2  var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.093  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.389  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "\n",
       "[2 rows x 200 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is composed in total of 200 000 single inputs (therefore the training and testing datasets each contain 100 000 inputs). Each input has 200 features. This high number of features justifies the use of a Bayesian approach compared to other machine learning meathods. As a matter of fact, due to the class independence assumption, the model doesn't have to take into account any possible correlation between the different features and therefore needs less input data to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:45.853086Z",
     "iopub.status.busy": "2021-05-27T10:54:45.852752Z",
     "iopub.status.idle": "2021-05-27T10:54:45.859517Z",
     "shell.execute_reply": "2021-05-27T10:54:45.857747Z",
     "shell.execute_reply.started": "2021-05-27T10:54:45.853056Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_posterior(X, y, sigma2priorweights, sigma2noise):\n",
    "    Sigma_inverse =    1/sigma2noise*X.T@X + np.diag([sigma2priorweights]*len(X[0]))\n",
    "    posterior_mu = np.linalg.solve(Sigma_inverse, X.T@y)/sigma2noise\n",
    "    posterior_Sigma =  np.linalg.solve(Sigma_inverse, np.identity(len(Sigma_inverse)))\n",
    "    return posterior_mu, posterior_Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:45.861456Z",
     "iopub.status.busy": "2021-05-27T10:54:45.860952Z",
     "iopub.status.idle": "2021-05-27T10:54:45.873426Z",
     "shell.execute_reply": "2021-05-27T10:54:45.872264Z",
     "shell.execute_reply.started": "2021-05-27T10:54:45.861419Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_predictive(Xnew, w_posterior_mu, w_posterior_Sigma, sigma2noise):\n",
    "    y_posterior_mu = Xnew@w_posterior_mu\n",
    "    #y_posterior_Sigma = sigma2noise + Xnew@w_posterior_Sigma@Xnew.T\n",
    "    return y_posterior_mu #,y_posterior_Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to transform the dataframes into numpy arrays in order to be able to compute the posterior.\n",
    "The input will then be in the right format to apply linear regression as for each input point (represented on a row of the array), the features are in different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:45.875444Z",
     "iopub.status.busy": "2021-05-27T10:54:45.874951Z",
     "iopub.status.idle": "2021-05-27T10:54:45.886419Z",
     "shell.execute_reply": "2021-05-27T10:54:45.885020Z",
     "shell.execute_reply.started": "2021-05-27T10:54:45.875405Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:45.889873Z",
     "iopub.status.busy": "2021-05-27T10:54:45.889402Z",
     "iopub.status.idle": "2021-05-27T10:54:46.167750Z",
     "shell.execute_reply": "2021-05-27T10:54:46.166519Z",
     "shell.execute_reply.started": "2021-05-27T10:54:45.889838Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma2noise = 1\n",
    "sigma2priorweights = 1\n",
    "w_posterior_mu, w_posterior_Sigma = compute_posterior(X_train, y_train, sigma2priorweights, sigma2noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:46.171405Z",
     "iopub.status.busy": "2021-05-27T10:54:46.170502Z",
     "iopub.status.idle": "2021-05-27T10:54:46.179549Z",
     "shell.execute_reply": "2021-05-27T10:54:46.178371Z",
     "shell.execute_reply.started": "2021-05-27T10:54:46.171346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.08168387e-06  2.04199094e-09 -7.83109906e-09 ... -1.13698658e-08\n",
      "   7.13138344e-09 -2.58127466e-09]\n",
      " [ 2.04199094e-09  6.13091896e-07 -1.97418983e-09 ...  1.93513182e-08\n",
      "   3.72479156e-09 -3.22587927e-10]\n",
      " [-7.83109906e-09 -1.97418983e-09  1.43915291e-06 ...  1.77215026e-08\n",
      "   2.96181137e-09 -2.37691051e-09]\n",
      " ...\n",
      " [-1.13698658e-08  1.93513182e-08  1.77215026e-08 ...  1.17772909e-05\n",
      "  -8.19464307e-09 -6.46639263e-10]\n",
      " [ 7.13138344e-09  3.72479156e-09  2.96181137e-09 ... -8.19464307e-09\n",
      "   1.10035885e-06  1.58767682e-09]\n",
      " [-2.58127466e-09 -3.22587927e-10 -2.37691051e-09 ... -6.46639263e-10\n",
      "   1.58767682e-09  9.15870342e-08]]\n"
     ]
    }
   ],
   "source": [
    "print(w_posterior_Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of the posterior characterizes the dispersion of the parameter. The low values show that the uncertainty on the model parameter is small. The larger values on the diagonal compared to the values in the rest of the covariance matrix strenghtens the previous assumption of uncorrelated features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted outputs are floats between 0 and 1. Therefore, in order to classify the predictions into two different classes, one has to find the threshold dividing the predictions. If the threshold value is 0.5, the predictions are therefore classified accordingly to their distance to the labels. Therefore a prediction of 0.3 is closer to 0 and will be classified as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:46.182712Z",
     "iopub.status.busy": "2021-05-27T10:54:46.181793Z",
     "iopub.status.idle": "2021-05-27T10:54:46.219029Z",
     "shell.execute_reply": "2021-05-27T10:54:46.217846Z",
     "shell.execute_reply.started": "2021-05-27T10:54:46.182651Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_posterior_mu = compute_predictive(X_test, w_posterior_mu, w_posterior_Sigma, sigma2noise) \n",
    "y_pred = np.array(y_posterior_mu > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:46.221842Z",
     "iopub.status.busy": "2021-05-27T10:54:46.220982Z",
     "iopub.status.idle": "2021-05-27T10:54:46.404038Z",
     "shell.execute_reply": "2021-05-27T10:54:46.403194Z",
     "shell.execute_reply.started": "2021-05-27T10:54:46.221785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90003    26]\n",
      " [ 9710   261]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_test = y_test_df.to_numpy()\n",
    "cm_linear_regression = confusion_matrix(y_test, y_pred)\n",
    "print(cm_linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> From the confusion matrix, we can see that the majority of the errors come from data labelled as 1 but classified as 0. (threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:46.406072Z",
     "iopub.status.busy": "2021-05-27T10:54:46.405468Z",
     "iopub.status.idle": "2021-05-27T10:54:46.419908Z",
     "shell.execute_reply": "2021-05-27T10:54:46.418635Z",
     "shell.execute_reply.started": "2021-05-27T10:54:46.406023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of linear regression : 0.90264\n"
     ]
    }
   ],
   "source": [
    "accuracy_linear_regression = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of linear regression : {}'.format(accuracy_linear_regression))\n",
    "error_rate_linear_regression = 1 - accuracy_linear_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> We obtain a 90% accuracy (which is the same accuracy than if all the data was predicted as 0). This accuracy remains around 90% with a threshold from 0.3 to 1 (at 1 all the labels are classified as 0 thus the 90% accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2A : Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:46.423382Z",
     "iopub.status.busy": "2021-05-27T10:54:46.423068Z",
     "iopub.status.idle": "2021-05-27T10:54:47.528900Z",
     "shell.execute_reply": "2021-05-27T10:54:47.527961Z",
     "shell.execute_reply.started": "2021-05-27T10:54:46.423351Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def set_seed(seed: int=0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:47.530438Z",
     "iopub.status.busy": "2021-05-27T10:54:47.530149Z",
     "iopub.status.idle": "2021-05-27T10:54:47.537241Z",
     "shell.execute_reply": "2021-05-27T10:54:47.534557Z",
     "shell.execute_reply.started": "2021-05-27T10:54:47.530409Z"
    }
   },
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:47.538962Z",
     "iopub.status.busy": "2021-05-27T10:54:47.538647Z",
     "iopub.status.idle": "2021-05-27T10:54:47.549885Z",
     "shell.execute_reply": "2021-05-27T10:54:47.548648Z",
     "shell.execute_reply.started": "2021-05-27T10:54:47.538911Z"
    }
   },
   "outputs": [],
   "source": [
    "class BernoulliLikelihood():\n",
    "    def logdensity(self, y, p):\n",
    "        return y*np.log(p) + (1-y)*np.log(1-p)\n",
    "\n",
    "class NormalPrior():\n",
    "    def __init__(self, sigma2x):\n",
    "        self.sigma2x = sigma2x\n",
    "        \n",
    "    def logdensity(self, x):\n",
    "        return -1/(2*self.sigma2x)*x.T@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:47.551721Z",
     "iopub.status.busy": "2021-05-27T10:54:47.551398Z",
     "iopub.status.idle": "2021-05-27T10:54:47.564307Z",
     "shell.execute_reply": "2021-05-27T10:54:47.563096Z",
     "shell.execute_reply.started": "2021-05-27T10:54:47.551693Z"
    }
   },
   "outputs": [],
   "source": [
    "class MHSampler():\n",
    "    @property\n",
    "    def samples(self):\n",
    "        return self._samples\n",
    "    @samples.getter    \n",
    "    def samples(self):\n",
    "        return np.asarray(self._samples)\n",
    "    \n",
    "    def __init__(self, initial_sample, likelihood, prior):\n",
    "        self.likelihood = likelihood\n",
    "        self.prior = prior\n",
    "        self._samples = [initial_sample]\n",
    "        self.acceptance_rate = 0\n",
    "        \n",
    "        \n",
    "    def unnormalized_logposterior(self, w, X, y):\n",
    "        log_likelihood = self.likelihood.logdensity(y, logistic((w.T@X)))\n",
    "        log_prior = self.prior.logdensity(w)\n",
    "        return (log_likelihood + log_prior)[0][0]\n",
    "\n",
    "    def step(self, X, y, step_proposal):\n",
    "        w_prev = self._samples[-1]\n",
    "        w_proposal = np.random.randn(200, 1)*step_proposal + w_prev \n",
    "        \n",
    "        log_gw_prev = self.unnormalized_logposterior(w_prev, X, y)\n",
    "        log_gw_proposal = self.unnormalized_logposterior(w_proposal, X, y)\n",
    "        acceptance_ratio = np.exp(log_gw_proposal - log_gw_prev) ###TO COMPLETE\n",
    "        \n",
    "        if acceptance_ratio >=1:\n",
    "            self._samples.append(w_proposal)\n",
    "        else:\n",
    "            u = np.random.uniform(0,1)\n",
    "            if u<=acceptance_ratio:\n",
    "                self._samples.append(w_proposal)\n",
    "                self.acceptance_rate += 1\n",
    "            else:\n",
    "                self._samples.append(w_prev)\n",
    "        return min(acceptance_ratio, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:54:47.566557Z",
     "iopub.status.busy": "2021-05-27T10:54:47.566115Z",
     "iopub.status.idle": "2021-05-27T10:55:41.207540Z",
     "shell.execute_reply": "2021-05-27T10:55:41.206314Z",
     "shell.execute_reply.started": "2021-05-27T10:54:47.566506Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in multiply\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "number_steps = 1000\n",
    "step_size = 10**(-1)\n",
    "likelihood = BernoulliLikelihood()\n",
    "prior = NormalPrior(1)\n",
    "\n",
    "starting_point = np.random.randn(200, 1)\n",
    "sampler = MHSampler(starting_point, likelihood, prior)\n",
    "for _ in range(number_steps):\n",
    "        sampler.step(X_train.T, y_train, step_size)\n",
    "samples_MCMC = sampler.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B : Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the variational inference algorithm we need to normalize the features of the inputs. As a matter of fact, if the features aren't noramlized, the gradients can either vanish or explode over cascaded layers of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:41.216284Z",
     "iopub.status.busy": "2021-05-27T10:55:41.213241Z",
     "iopub.status.idle": "2021-05-27T10:55:42.736052Z",
     "shell.execute_reply": "2021-05-27T10:55:42.735238Z",
     "shell.execute_reply.started": "2021-05-27T10:55:41.216196Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_df)\n",
    "X = X_scaler.transform(X_df)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_norm, X_test_norm, y_train_df_norm, y_test_df_norm = train_test_split(\n",
    "    X, y_df, random_state=1, test_size=0.5)\n",
    "y_train_norm = y_train_df_norm.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.737538Z",
     "iopub.status.busy": "2021-05-27T10:55:42.737147Z",
     "iopub.status.idle": "2021-05-27T10:55:42.818981Z",
     "shell.execute_reply": "2021-05-27T10:55:42.818097Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.737499Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import scipy.spatial\n",
    "import time \n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def set_seed(seed: int=0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "def args_as_tensors(*index):\n",
    "    \"\"\"A simple decorator to convert numpy arrays to torch tensors\"\"\"\n",
    "    def decorator(method):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            converted_args = [torch.tensor(a).float() \n",
    "                              if i in index and type(a) is np.ndarray else a \n",
    "                              for i, a in enumerate(args)]\n",
    "            return method(*converted_args, **kwargs)\n",
    "        return wrapper  \n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.820741Z",
     "iopub.status.busy": "2021-05-27T10:55:42.820339Z",
     "iopub.status.idle": "2021-05-27T10:55:42.826360Z",
     "shell.execute_reply": "2021-05-27T10:55:42.825222Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.820701Z"
    }
   },
   "outputs": [],
   "source": [
    "jitter = 1e-10\n",
    "\n",
    "class Distribution(nn.Module):  \n",
    "    pass\n",
    "\n",
    "class Bernoulli(Distribution):\n",
    "    @args_as_tensors(1, 2)\n",
    "    def logdensity(self, y, p):\n",
    "        return y*torch.log(p+jitter) + (1-y)*torch.log(1-p+jitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.827903Z",
     "iopub.status.busy": "2021-05-27T10:55:42.827632Z",
     "iopub.status.idle": "2021-05-27T10:55:42.839850Z",
     "shell.execute_reply": "2021-05-27T10:55:42.839170Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.827877Z"
    }
   },
   "outputs": [],
   "source": [
    "class NormalDiagonal(Distribution):\n",
    "    @property\n",
    "    def var(self):\n",
    "        return self.logvar.exp()\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return 'train=%s' % self.train\n",
    "    \n",
    "    def __init__(self, d, train=True):\n",
    "        super(NormalDiagonal, self).__init__()\n",
    "        self.train = train\n",
    "        self.d = d\n",
    "        self.mean = nn.Parameter(torch.zeros(d), requires_grad=train)\n",
    "        self.logvar = nn.Parameter(torch.zeros(d), requires_grad=train)\n",
    "    \n",
    "    def sample(self, n=1):\n",
    "        eps = torch.randn(n,self.d,requires_grad=self.train) \n",
    "        samples = self.mean + eps*(torch.sqrt((self.var)))\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.841631Z",
     "iopub.status.busy": "2021-05-27T10:55:42.841097Z",
     "iopub.status.idle": "2021-05-27T10:55:42.857969Z",
     "shell.execute_reply": "2021-05-27T10:55:42.857236Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.841586Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import total_ordering\n",
    "\n",
    "_KL_REGISTRY = {}  # Source of truth mapping a few general (type, type) pairs to functions.\n",
    "_KL_MEMOIZE = {}  # Memoized version mapping many specific (type, type) pairs to functions.\n",
    "\n",
    "@total_ordering\n",
    "class _Match(object):\n",
    "    __slots__ = ['types']\n",
    "\n",
    "    def __init__(self, *types):\n",
    "        self.types = types\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.types == other.types\n",
    "\n",
    "    def __le__(self, other):\n",
    "        for x, y in zip(self.types, other.types):\n",
    "            if not issubclass(x, y):\n",
    "                return False\n",
    "            if x is not y:\n",
    "                break\n",
    "        return True\n",
    "\n",
    "def _dispatch_kl(type_q, type_p):\n",
    "    matches = [(super_q, super_p) for super_q, super_p in _KL_REGISTRY\n",
    "               if issubclass(type_q, super_q) and issubclass(type_p, super_p)]\n",
    "    if not matches:\n",
    "        return NotImplemented\n",
    "    left_q, left_p = min(_Match(*m) for m in matches).types\n",
    "    right_p, right_q = min(_Match(*reversed(m)) for m in matches).types\n",
    "    left_fun = _KL_REGISTRY[left_q, left_p]\n",
    "    right_fun = _KL_REGISTRY[right_q, right_p]\n",
    "    if left_fun is not right_fun:\n",
    "        logger.warning('Ambiguous kl_divergence({}, {}). Please register_kl({}, {})'.format(\n",
    "            type_q.__name__, type_p.__name__, left_q.__name__, right_p.__name__))\n",
    "    return left_fun\n",
    "\n",
    "\n",
    "def register_kl(type_q, type_p):\n",
    "    \"\"\"\n",
    "    Decorator to register a pairwise function with kl_divergence.\n",
    "    Usage:\n",
    "\n",
    "        @register_kl(Normal, Normal)\n",
    "        def kl_normal_normal(q, p):\n",
    "            # insert implementation here\n",
    "    \"\"\"\n",
    "    if not isinstance(type_q, type) and issubclass(type_q, BaseDistribution):\n",
    "        raise TypeError('Expected type_q to be a Distribution subclass but got {}'.format(type_q))\n",
    "    if not isinstance(type_p, type) and issubclass(type_p, BaseDistribution):\n",
    "        raise TypeError('Expected type_p to be a Distribution subclass but got {}'.format(type_p))\n",
    "    \n",
    "    def decorator(fun):\n",
    "        _KL_REGISTRY[type_q, type_p] = fun\n",
    "        _KL_MEMOIZE.clear()  # reset since lookup order may have changed\n",
    "        print('KL divergence between \\'%s\\' and \\'%s\\' registered.' % (type_q.__name__, type_p.__name__))\n",
    "        return fun\n",
    "    return decorator\n",
    "\n",
    "\n",
    "def kl_divergence(q, p):\n",
    "    r\"\"\"Compute Kullback-Leibler divergence KL(p|q) between two distributions.\"\"\"\n",
    "    try:\n",
    "        fun = _KL_MEMOIZE[type(q), type(p)]\n",
    "    except KeyError:\n",
    "        fun = _dispatch_kl(type(q), type(p))\n",
    "        _KL_MEMOIZE[type(q), type(p)] = fun\n",
    "    if fun is NotImplemented:\n",
    "        raise NotImplementedError('KL divergence for pair %s - %s not registered' % (type(q).__name__,\n",
    "                                                                                     type(p).__name__))\n",
    "    return fun(q, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.862382Z",
     "iopub.status.busy": "2021-05-27T10:55:42.861928Z",
     "iopub.status.idle": "2021-05-27T10:55:42.876949Z",
     "shell.execute_reply": "2021-05-27T10:55:42.875976Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.862347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL divergence between 'NormalDiagonal' and 'NormalDiagonal' registered.\n"
     ]
    }
   ],
   "source": [
    "@register_kl(NormalDiagonal, NormalDiagonal)\n",
    "def _normaldiagonal_normaldiagonal(q, p):\n",
    "    kl = (1/2) * torch.sum(p.logvar - q.logvar + (q.var + (q.mean - p.mean)**2)/p.var - 1)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.878995Z",
     "iopub.status.busy": "2021-05-27T10:55:42.878673Z",
     "iopub.status.idle": "2021-05-27T10:55:42.890499Z",
     "shell.execute_reply": "2021-05-27T10:55:42.889397Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.878967Z"
    }
   },
   "outputs": [],
   "source": [
    "def logistic_tensor(z):\n",
    "    return 1/(1 + torch.exp(-z))\n",
    "\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        \n",
    "        self.prior_w = NormalDiagonal(input_dim)## *** TO COMPLETE *** ##\n",
    "        self.posterior_w = NormalDiagonal(input_dim) ## *** TO COMPLETE *** ##\n",
    "        \n",
    "    @args_as_tensors(1)\n",
    "    def predict_y(self, X, mc_samples=1):\n",
    "        w_samples = self.posterior_w.sample(mc_samples)\n",
    "        w_samples=torch.unsqueeze(w_samples, dim=2)\n",
    "        y_samples = logistic_tensor(X @ w_samples)\n",
    "        \n",
    "        return y_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.892485Z",
     "iopub.status.busy": "2021-05-27T10:55:42.892169Z",
     "iopub.status.idle": "2021-05-27T10:55:42.905906Z",
     "shell.execute_reply": "2021-05-27T10:55:42.904941Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.892455Z"
    }
   },
   "outputs": [],
   "source": [
    "class VariationalObjective(nn.Module):    \n",
    "    def __init__(self, model, likelihood, N, mc_samples):\n",
    "        super(VariationalObjective, self).__init__()\n",
    "        self.N = N\n",
    "        self.model = model\n",
    "        self.likelihood = likelihood\n",
    "        self.mc_samples = mc_samples\n",
    "        \n",
    "    def expected_loglikelihood(self, Xbatch, ybatch):\n",
    "        ypred = model.predict_y(Xbatch, self.mc_samples)\n",
    "        logliks = self.likelihood.logdensity(ybatch, ypred)\n",
    "        return - (self.N/(self.mc_samples*Xbatch.shape[0]))*torch.sum(logliks)\n",
    "\n",
    "    \n",
    "    def kl(self):\n",
    "        return kl_divergence(self.model.posterior_w, self.model.prior_w) \n",
    "    \n",
    "    def compute_objective(self, Xbatch, ybatch):\n",
    "        return self.expected_loglikelihood(Xbatch, ybatch) + self.kl() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.908163Z",
     "iopub.status.busy": "2021-05-27T10:55:42.907431Z",
     "iopub.status.idle": "2021-05-27T10:55:42.924968Z",
     "shell.execute_reply": "2021-05-27T10:55:42.924115Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.908110Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, X, y, minibatch_size):\n",
    "        self.X = X\n",
    "        self.y = y \n",
    "        self.minibatch_size = min(minibatch_size, len(self.X))\n",
    "        self._i = 0  \n",
    "    def next_batch(self):  \n",
    "        if len(self.X) <= self._i + self.minibatch_size:\n",
    "            shuffle = np.random.permutation(len(self.X))\n",
    "            self.X = self.X[shuffle]\n",
    "            self.y = self.y[shuffle]\n",
    "            Xbatch = self.X[self._i:]\n",
    "            ybatch = self.y[self._i:]\n",
    "            self._i = 0\n",
    "            return Xbatch, ybatch\n",
    "\n",
    "        Xbatch = self.X[self._i:self._i + self.minibatch_size]\n",
    "        ybatch = self.y[self._i:self._i + self.minibatch_size]\n",
    "        self._i += self.minibatch_size\n",
    "        return Xbatch, ybatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.927140Z",
     "iopub.status.busy": "2021-05-27T10:55:42.926434Z",
     "iopub.status.idle": "2021-05-27T10:55:42.941079Z",
     "shell.execute_reply": "2021-05-27T10:55:42.940046Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.927032Z"
    }
   },
   "outputs": [],
   "source": [
    "class Summary:\n",
    "    @property\n",
    "    def data(self):\n",
    "        data = pd.DataFrame(self._data, columns=['step', self.name, 'time'])\n",
    "        data.time = data.time - data.time.iloc[0]\n",
    "        return data\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \"\"\"A simple class to store some values during optimization\"\"\"\n",
    "        self.name = str(name)\n",
    "        self._data = []\n",
    "    \n",
    "    def append(self, step, value):\n",
    "        self._data.append([step, float(value.detach().numpy()), time.time()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:55:42.943632Z",
     "iopub.status.busy": "2021-05-27T10:55:42.942898Z",
     "iopub.status.idle": "2021-05-27T10:57:19.337096Z",
     "shell.execute_reply": "2021-05-27T10:57:19.336165Z",
     "shell.execute_reply.started": "2021-05-27T10:55:42.943499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [999/1000], Loss: 31790.1445\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "lr = 10**(-5)\n",
    "batch_size = 100\n",
    "\n",
    "dataset = Dataset(X_train_norm, y_train_norm, minibatch_size = batch_size)\n",
    "likelihood = Bernoulli()\n",
    "model = LogisticRegression(len(X_train_norm[0]))\n",
    "\n",
    "nelbo = VariationalObjective(model, likelihood, len(X_train_norm[0]), mc_samples = 1000)\n",
    "nelbo_summary = Summary('nelbo')\n",
    "nll_summary = Summary('expected_loglik')\n",
    "kl_summary = Summary('kl')\n",
    "from IPython.display import clear_output\n",
    "optim = torch.optim.SGD(filter(lambda p: p.requires_grad,model.parameters()), lr = lr) #SGD\n",
    "num_iterations = 1000\n",
    "\n",
    "for step in range(num_iterations):\n",
    "    optim.zero_grad()\n",
    "    Xbatch, ybatch = dataset.next_batch()\n",
    "    loss = nelbo.compute_objective(Xbatch, ybatch)\n",
    "\n",
    "    nelbo_summary.append(step, loss)\n",
    "    nll_summary.append(step, loss - nelbo.kl())\n",
    "    kl_summary.append(step, nelbo.kl())\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    clear_output()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(step, num_iterations, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C : Predictive distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:57:19.339371Z",
     "iopub.status.busy": "2021-05-27T10:57:19.338893Z",
     "iopub.status.idle": "2021-05-27T10:57:19.345414Z",
     "shell.execute_reply": "2021-05-27T10:57:19.344069Z",
     "shell.execute_reply.started": "2021-05-27T10:57:19.339323Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(x_new, w_samples):\n",
    "    p = 0\n",
    "    for w in w_samples:\n",
    "        p += logistic(w.T @ x_new)\n",
    "    return p / len(w_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:57:19.347741Z",
     "iopub.status.busy": "2021-05-27T10:57:19.347196Z",
     "iopub.status.idle": "2021-05-27T10:58:00.949869Z",
     "shell.execute_reply": "2021-05-27T10:58:00.948598Z",
     "shell.execute_reply.started": "2021-05-27T10:57:19.347695Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_mcmc = np.array(predict(X_test.T, samples_MCMC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:58:00.956015Z",
     "iopub.status.busy": "2021-05-27T10:58:00.955502Z",
     "iopub.status.idle": "2021-05-27T10:58:01.939124Z",
     "shell.execute_reply": "2021-05-27T10:58:01.938017Z",
     "shell.execute_reply.started": "2021-05-27T10:58:00.955953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loglikelihood for MCMC : -0.6189762133470926\n",
      "Error rate for MCMC : 0.30042\n",
      "[[66838 23191]\n",
      " [ 6851  3120]]\n"
     ]
    }
   ],
   "source": [
    "log_likelihood_mcmc = BernoulliLikelihood().logdensity(y_test, predictions_mcmc[0])\n",
    "log_likelihood_mcmc_no_nan = [x for x in log_likelihood_mcmc if (~np.isnan(x) and ~np.isinf(x))]\n",
    "mean_log_likelihood_mcmc = np.mean(log_likelihood_mcmc_no_nan)\n",
    "print('Mean loglikelihood for MCMC : {}'.format(mean_log_likelihood_mcmc))\n",
    "\n",
    "y_pred_mcmc = np.array(predictions_mcmc > 0.5).astype(int)\n",
    "acc_mcmc = accuracy_score(y_test, y_pred_mcmc[0])\n",
    "error_rate_mcmc = 1 - acc_mcmc\n",
    "print('Error rate for MCMC : {}'.format(error_rate_mcmc))\n",
    "\n",
    "cm_mcmc = confusion_matrix(y_test, y_pred_mcmc[0])\n",
    "print(cm_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions for variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:58:01.941138Z",
     "iopub.status.busy": "2021-05-27T10:58:01.940704Z",
     "iopub.status.idle": "2021-05-27T10:58:02.104735Z",
     "shell.execute_reply": "2021-05-27T10:58:02.103624Z",
     "shell.execute_reply.started": "2021-05-27T10:58:01.941091Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_vi = model.predict_y(X_test_norm).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:58:02.106779Z",
     "iopub.status.busy": "2021-05-27T10:58:02.106377Z",
     "iopub.status.idle": "2021-05-27T10:58:03.011139Z",
     "shell.execute_reply": "2021-05-27T10:58:03.009679Z",
     "shell.execute_reply.started": "2021-05-27T10:58:02.106736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loglikelihood for VI : -1.5140644311904907\n",
      "Error rate for VI : 0.49349\n",
      "[[45387 44642]\n",
      " [ 4707  5264]]\n"
     ]
    }
   ],
   "source": [
    "log_likelihood_vi = Bernoulli().logdensity(y_test, predictions_vi[0].T[0]).detach().numpy()\n",
    "log_likelihood_vi_no_nan = [x for x in log_likelihood_vi if (~np.isnan(x) and ~np.isinf(x))]\n",
    "mean_log_likelihood_vi = np.mean(log_likelihood_vi_no_nan)\n",
    "print('Mean loglikelihood for VI : {}'.format(mean_log_likelihood_vi))\n",
    "\n",
    "y_pred_vi = np.array(predictions_vi > 0.5).astype(int)\n",
    "acc_vi = accuracy_score(y_test, y_pred_vi[0])\n",
    "error_rate_vi = 1 - acc_vi\n",
    "print('Error rate for VI : {}'.format(error_rate_vi))\n",
    "\n",
    "cm_vi = confusion_matrix(y_test, y_pred_vi[0])\n",
    "print(cm_vi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T14:42:52.628978Z",
     "iopub.status.busy": "2021-05-25T14:42:52.628638Z",
     "iopub.status.idle": "2021-05-25T14:42:52.634758Z",
     "shell.execute_reply": "2021-05-25T14:42:52.633722Z",
     "shell.execute_reply.started": "2021-05-25T14:42:52.628948Z"
    }
   },
   "source": [
    "## 2D : Tuning of Metropolis Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T10:58:03.012975Z",
     "iopub.status.busy": "2021-05-27T10:58:03.012616Z",
     "iopub.status.idle": "2021-05-27T11:01:08.269451Z",
     "shell.execute_reply": "2021-05-27T11:01:08.266051Z",
     "shell.execute_reply.started": "2021-05-27T10:58:03.012939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.70931\n",
      "0.199\n",
      "0.01\n",
      "0.52143\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "number_steps = 1000\n",
    "step_size = [10**(-i) for i in range(1,3)]\n",
    "accuracy = []\n",
    "acceptance_rate = []\n",
    "\n",
    "for s in step_size:\n",
    "    likelihood = BernoulliLikelihood()\n",
    "    prior = NormalPrior(1)\n",
    "\n",
    "    starting_point = np.random.randn(200, 1)\n",
    "    sampler = MHSampler(starting_point, likelihood, prior)\n",
    "    \n",
    "    for _ in range(number_steps):\n",
    "        sampler.step(X_train.T, y_train, s)\n",
    "    ps = predict(X_test.T, sampler.samples[round(0.1 * number_steps):]) #burn-in of 10% of the samples\n",
    "    y_pred = np.array(ps > 0.5).astype(int)\n",
    "    acc = accuracy_score(y_test, y_pred[0])\n",
    "    accuracy.append(acc)\n",
    "    acceptance_rate.append(sampler.acceptance_rate/number_steps)\n",
    "    print(s)\n",
    "    print(acc)\n",
    "    print(sampler.acceptance_rate/number_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 1000 samples\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Step size</th>\n",
    "<th>Accuracy</th>\n",
    "<th>Acceptance rate</th>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "<td>0.0001</td>\n",
    "<td>0.88</td>\n",
    "<td>0.50</td>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "<td>0.001</td>\n",
    "<td>0.88</td>\n",
    "<td>0.47</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0.01</td>\n",
    "<td>0.52</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0.1</td>\n",
    "<td>0.70</td>\n",
    "<td>0.199</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0.2</td>\n",
    "<td>0.51</td>\n",
    "<td>0.167</td>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "<td>0.3</td>\n",
    "<td>0.20</td>\n",
    "<td>0.092</td>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "<td>0.4</td>\n",
    "<td>0.12</td>\n",
    "<td>0.001</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "The step proposal determines the variance:\n",
    "- a low variance (small step size) will lead to highly correlated samples\n",
    "- a high variance (larger step size) will lead to a lower acceptance rate as many samples will be rejected as they don't belong to the aread of high density in the posterior space. As shown in the results, the acceptance rate decreases with the augmentation of the step size.\n",
    "\n",
    "The optimal acceptance rate for multi dimension distributions is believed to be equal to 0.234, which is coherent with the results obtained : the higher accuracy is achieved when the acceptance rate is close to this value.\n",
    "\n",
    "In order to ensure that samples are representative of samples of the posterior over model\n",
    "parameters, one can use the burn-in method. For a step size of 0.1 and 1000 samples, the accuracy is now 71% (instead of 70%). This small difference is due to the fact that if there are enough samples, the first samples coming from a random point will not matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T12:37:19.775439Z",
     "iopub.status.busy": "2021-05-25T12:37:19.774587Z",
     "iopub.status.idle": "2021-05-25T12:37:19.780085Z",
     "shell.execute_reply": "2021-05-25T12:37:19.778852Z",
     "shell.execute_reply.started": "2021-05-25T12:37:19.775385Z"
    }
   },
   "source": [
    "## 2E : Tuning of Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> In order to tune the variational inference algorithm, a grid search was implemented on the learning rate and the minibatch size in order to find the optimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T11:01:08.272222Z",
     "iopub.status.busy": "2021-05-27T11:01:08.271688Z",
     "iopub.status.idle": "2021-05-27T11:07:35.063113Z",
     "shell.execute_reply": "2021-05-27T11:07:35.061570Z",
     "shell.execute_reply.started": "2021-05-27T11:01:08.272172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lr: 1e-07, Batch: 100, Epoch [999/1000], Loss: 111826.9844\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "lr = [10**(-i) for i in range(5,8)]\n",
    "minibatch_size = [10**i for i in range(3)]\n",
    "accuracy = np.zeros((len(lr), len(minibatch_size)))\n",
    "\n",
    "for l in range(len(lr)):\n",
    "    for s in range(len(minibatch_size)):\n",
    "        \n",
    "        dataset = Dataset(X_train_norm, y_train, minibatch_size = minibatch_size[s])\n",
    "\n",
    "        likelihood = Bernoulli()\n",
    "        model = LogisticRegression(len(X_train[0]))\n",
    "\n",
    "        nelbo = VariationalObjective(model, likelihood, len(X_train_norm[0]), mc_samples = 1000)\n",
    "        nelbo_summary = Summary('nelbo')\n",
    "        nll_summary = Summary('expected_loglik')\n",
    "        kl_summary = Summary('kl')\n",
    "        from IPython.display import clear_output\n",
    "        #optim = torch.optim.SGD(filter(lambda p: p.requires_grad,model.parameters()), lr = lr[l])\n",
    "        #optim = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()), lr = lr[l])\n",
    "        optim = torch.optim.Adagrad(filter(lambda p: p.requires_grad,model.parameters()), lr = lr[l])\n",
    "        num_iterations = 1000\n",
    "\n",
    "        for step in range(num_iterations):\n",
    "            optim.zero_grad()\n",
    "            Xbatch, ybatch = dataset.next_batch()\n",
    "            loss = nelbo.compute_objective(Xbatch, ybatch)\n",
    "\n",
    "            nelbo_summary.append(step, loss)\n",
    "            nll_summary.append(step, loss - nelbo.kl())\n",
    "            kl_summary.append(step, nelbo.kl())\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            clear_output()\n",
    "            print('Lr: {}, Batch: {}, Epoch [{}/{}], Loss: {:.4f}'.format(lr[l], minibatch_size[s], step, num_iterations, loss.item()))\n",
    "            \n",
    "        ypred = model.predict_y(X_test_norm).detach().numpy()[0].T[0]\n",
    "        y_pred = np.array(ypred > 0.5).astype(int)\n",
    "\n",
    "        accuracy[l][s] = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T11:12:34.302828Z",
     "iopub.status.busy": "2021-05-27T11:12:34.302348Z",
     "iopub.status.idle": "2021-05-27T11:12:34.310096Z",
     "shell.execute_reply": "2021-05-27T11:12:34.308788Z",
     "shell.execute_reply.started": "2021-05-27T11:12:34.302792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal learning rate : 1e-05, mini-batch size : 1\n"
     ]
    }
   ],
   "source": [
    "(l, s) = np.unravel_index(accuracy.argmax(), accuracy.shape)\n",
    "print('Optimal learning rate : {}, mini-batch size : {}'.format(lr[l], minibatch_size[s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Choice of the optimizer\n",
    "\n",
    "For lr = 10**(-5), minibatch_size = 100, 1000 steps\n",
    "<table>\n",
    "<tr>\n",
    "<th>Optimizer</th>\n",
    "<th>Accuracy</th>\n",
    "<th>Loss at Epoch 1000</th>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "<td>SGD</td>\n",
    "<td>50.7 %</td>\n",
    "<td>531 790</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Adam</td>\n",
    "<td>50.8%</td>\n",
    "<td>111 228</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Adagrad</td>\n",
    "<td>50.8%</td>\n",
    "<td>116 634</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "The choice of the optimizer doesn't in fact have much effect on the quality of the prediction. However the Stochastic Gradient Descent (SGD) allows us to reach a lower loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T11:07:35.075424Z",
     "iopub.status.busy": "2021-05-27T11:07:35.074947Z",
     "iopub.status.idle": "2021-05-27T11:07:35.090534Z",
     "shell.execute_reply": "2021-05-27T11:07:35.089415Z",
     "shell.execute_reply.started": "2021-05-27T11:07:35.075376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for Linear Regression : 0.09736\n",
      "Error rate for MCMC : 0.30042\n",
      "Error rate for Variational Inference: 0.49349\n"
     ]
    }
   ],
   "source": [
    "print('Error rate for Linear Regression : {}'.format(error_rate_linear_regression))\n",
    "print('Error rate for MCMC : {}'.format(error_rate_mcmc))\n",
    "print('Error rate for Variational Inference: {}'.format(error_rate_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T11:14:42.413136Z",
     "iopub.status.busy": "2021-05-27T11:14:42.412705Z",
     "iopub.status.idle": "2021-05-27T11:14:42.421587Z",
     "shell.execute_reply": "2021-05-27T11:14:42.419951Z",
     "shell.execute_reply.started": "2021-05-27T11:14:42.413098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Linear Regression : \n",
      " [[90003    26]\n",
      " [ 9710   261]]\n",
      "Confusion Matrix for MCMC : \n",
      " [[66838 23191]\n",
      " [ 6851  3120]]\n",
      "Confusion Matrix for Variational Inference : \n",
      " [[45387 44642]\n",
      " [ 4707  5264]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for Linear Regression : \\n {}'.format(cm_linear_regression))\n",
    "print('Confusion Matrix for MCMC : \\n {}'.format(cm_mcmc))\n",
    "print('Confusion Matrix for Variational Inference : \\n {}'.format(cm_vi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite a lower error rate for linear regression, we can see that this performance is mainly due to the fact that most of the predictions are classified as '1'. The number of false positives is the highest (9710 for Linear Regression, 6851 for MCMC and 4707 for Variational Inference). Therefore as suggested in question B, the imbalanced dataset and the number of features (especially if considered uncorrelated) has an impact when evaluating the model. The \"bias\" towards the negative class in an imbalanced set originates from the-best-guess-is-majority-class-if-everything-else-is-equal, something which Naive Bayes is sensitive to (especially when a lot of features are involved), thus the high number of false positives for Linear Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T11:23:06.680781Z",
     "iopub.status.busy": "2021-05-27T11:23:06.680384Z",
     "iopub.status.idle": "2021-05-27T11:23:06.687631Z",
     "shell.execute_reply": "2021-05-27T11:23:06.686017Z",
     "shell.execute_reply.started": "2021-05-27T11:23:06.680748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loglikelihood for MCMC : -0.6189762133470926\n",
      "Mean loglikelihood for VI : -1.5140644311904907\n"
     ]
    }
   ],
   "source": [
    "print('Mean loglikelihood for MCMC : {}'.format(mean_log_likelihood_mcmc))\n",
    "print('Mean loglikelihood for VI : {}'.format(mean_log_likelihood_vi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the mean loglikelihood is closer to zero than the mean loglikelihood for Variational Inference meaning that the first has a likelihood closer to 1 than the other. As the likelihood function measures the goodness of fit of a statistical model to a sample of data for given values of the unknown parameters, the results are coherent. As a matter of fact, in Variationanal Inference a bias is introduced as we choose from a family of distributions instead of constructing an approximate distribution directly from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T11:32:07.434252Z",
     "iopub.status.busy": "2021-05-27T11:32:07.433288Z",
     "iopub.status.idle": "2021-05-27T11:32:08.715137Z",
     "shell.execute_reply": "2021-05-27T11:32:08.714054Z",
     "shell.execute_reply.started": "2021-05-27T11:32:07.434212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_mcmc_0_5 = [x for x in predictions_mcmc[0] if 0.45 < x < 0.55]\n",
    "predictions_vi_0_5 = [x for x in predictions_vi[0].T[0] if 0.45 < x < 0.55]\n",
    "\n",
    "n_bins = 100\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "fig.suptitle('Test points with a predictive distribution mean around 0.5 : between 0.45 and 0.55')\n",
    "axs[0].hist(predictions_mcmc_0_5, bins=n_bins)\n",
    "axs[0].title.set_text('Metropolis-Hastings')\n",
    "axs[1].hist(predictions_vi_0_5, bins=n_bins)\n",
    "axs[1].title.set_text('Variational Inference')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T11:29:03.320319Z",
     "iopub.status.busy": "2021-05-27T11:29:03.319885Z",
     "iopub.status.idle": "2021-05-27T11:29:05.665852Z",
     "shell.execute_reply": "2021-05-27T11:29:05.665030Z",
     "shell.execute_reply.started": "2021-05-27T11:29:03.320276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_mcmc_right = [predictions_mcmc[0][i] for i in range (len(predictions_mcmc[0])) if ((predictions_mcmc[0][i]>0.5).astype(int) == y_test[i])]\n",
    "predictions_vi_right = [predictions_vi[0].T[0][i] for i in range (len(predictions_vi[0])) if ((predictions_vi[0].T[0][i]>0.5).astype(int) == y_test[i])]\n",
    "predictions_mcmc_right = predictions_mcmc_right[:len(predictions_vi_right)]\n",
    "\n",
    "n_bins = 100\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "fig.suptitle('Test points rightly classified')\n",
    "axs[0].title.set_text('Metropolis-Hastings')\n",
    "axs[0].hist(predictions_mcmc_right, bins=n_bins)\n",
    "axs[1].title.set_text('Variational Inference')\n",
    "axs[1].hist(predictions_vi_right, bins=n_bins)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T11:29:17.620817Z",
     "iopub.status.busy": "2021-05-27T11:29:17.620444Z",
     "iopub.status.idle": "2021-05-27T11:29:19.735214Z",
     "shell.execute_reply": "2021-05-27T11:29:19.734494Z",
     "shell.execute_reply.started": "2021-05-27T11:29:17.620784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_mcmc_wrong = [predictions_mcmc[0][i] for i in range (len(predictions_mcmc[0])) if ((predictions_mcmc[0][i]>0.5).astype(int) != y_test[i])]\n",
    "predictions_vi_wrong = [predictions_vi[0].T[0][i] for i in range (len(predictions_vi[0])) if ((predictions_vi[0].T[0][i]>0.5).astype(int) != y_test[i])]\n",
    "predictions_vi_wrong = predictions_vi_wrong[:len(predictions_mcmc_wrong)]\n",
    "\n",
    "n_bins = 100\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "fig.suptitle('Test points wrongly classified')\n",
    "axs[0].title.set_text('Metropolis-Hastings')\n",
    "axs[0].hist(predictions_mcmc_wrong, bins=n_bins)\n",
    "axs[1].title.set_text('Variational Inference')\n",
    "axs[1].hist(predictions_vi_wrong, bins=n_bins)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs we can see that most of the righly classified points are labelled as '0' while the wrongly classified are mainly samples labelled as '0' but classified as '1'.\n",
    "The main difference between Metropolis-Hastings and Variational Inference is the predictive distribution. As a matter of fact, the Variational Inference one have fewer points towards 0.5 as shown in the first graph and tens to have a higher number of samples with a mean either closer to 0 or 1. The uncertainty on the predictions are therefore lower for the Variational Inference model than for the Metropolis Hastings algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus question : Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be an issue when trying to evaluate the second derivative of log_g in w_hat. I also trie coding my own second derivative using Taylor approximation but the multivariate case was complicated to handle. Due to a lack of time, I wasn't able to fix the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T12:23:58.622299Z",
     "iopub.status.busy": "2021-05-26T12:23:58.621919Z",
     "iopub.status.idle": "2021-05-26T12:23:58.635355Z",
     "shell.execute_reply": "2021-05-26T12:23:58.634403Z",
     "shell.execute_reply.started": "2021-05-26T12:23:58.622267Z"
    }
   },
   "outputs": [],
   "source": [
    "from jax import hessian\n",
    "import scipy\n",
    "\n",
    "class Laplace():\n",
    "    @property\n",
    "    def samples(self):\n",
    "        return self._samples\n",
    "    @samples.getter    \n",
    "    def samples(self):\n",
    "        return np.asarray(self._samples)\n",
    "    \n",
    "    def __init__(self, number_samples, likelihood, prior):\n",
    "        self.likelihood = likelihood\n",
    "        self.prior = prior\n",
    "        self.mean = []\n",
    "        self.n_samples = number_samples\n",
    "        self._samples = []\n",
    "    \n",
    "    def log_g(self, w, X, y):\n",
    "        w = w.reshape(200,1)\n",
    "        log_likelihood = self.likelihood.logdensity(y, logistic((w.T@X)))\n",
    "        log_prior = self.prior.logdensity(w)\n",
    "        return (log_likelihood + log_prior)[0][0]\n",
    "\n",
    "    def w_hat(self, X, y):\n",
    "        max_w = scipy.optimize.fmin(lambda w: -self.log_g(w, X, y), np.random.randn(200, 1))\n",
    "        return max_w\n",
    "    \n",
    "    def inv_sigma(self, X, y):\n",
    "        return - hessian(lambda w: self.log_g(w, X, y))(self.mean)\n",
    "    \n",
    "    def approx(self, X, y):\n",
    "        self.mean = self.w_hat(X,y).reshape(200,1)\n",
    "        print('mean ok')\n",
    "        sigma_inv = self.inv_sigma(X, y)\n",
    "        print('inv ok')\n",
    "        sigma = np.linalg.solve(sigma_inv, np.identity(len(sigma_inv)))\n",
    "        print('sigma ok')\n",
    "        self._samples = np.random.multivariate_normal(self.mean, sigma, self.n_samples)\n",
    "        return self._samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T12:26:37.848099Z",
     "iopub.status.busy": "2021-05-26T12:26:37.847492Z",
     "iopub.status.idle": "2021-05-26T12:40:33.342978Z",
     "shell.execute_reply": "2021-05-26T12:40:33.339689Z",
     "shell.execute_reply.started": "2021-05-26T12:26:37.84805Z"
    }
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "likelihood = BernoulliLikelihood()\n",
    "prior = NormalPrior(1)\n",
    "n_samples = 100\n",
    "sampler = Laplace(n_samples, likelihood, prior)\n",
    "sampler.approx(X_train.T, y_train)\n",
    "print(sampler.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
